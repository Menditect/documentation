# Process testing

## Definition

A process test consists of several steps, where multiple functions of the software are tested. The user and the system interact, and in some cases multiple users or integrating external systems are involved. Part of the process test could be verifying some deliverable as part of the result.

There may also be one or more processes in any Mendix App that are business-critical and therefore need to be regression-tested. 

A process test generally creates data that can be visually inspected in the Mendix app being tested. However part of the test should be cleaning up the data, to avoid uncontrolled growth of the data generated by the test, and also to avoid unique constraint runtime errors. 

## Structure

Recommended best practice is create a draft version of a process test when first creating it. Sometimes when executing the Test Configuration it could stop halfway because of a technical error. In that scenario it is possible to restore the data, by executing just one of the Test Suites (or one Test Case) in the Test Configuration. This is described below.

A process test in MTA typically looks like this:
- multiple Test Suites in one Test Configuration;
- the first Test Suite cleans up both masterdata and process data generated from the previous run of the Test Configuration;
- the second Test Suite creates masterdata;
- subsequent Test Suites deal with the actual process test;
- in these Test Suites, one or more Test Cases where each test case represents a user or component transaction, using data from the database from the previous Test Case;
- in these Test Cases, alternating Object and Microflow Teststeps, each using data from the previous one;
- continuous usage of asserts for checking the results;
- Data Variation to drive different scenario's of the process.

### Run a single Test Case

Running a single Test Case can be useful to restore data if a process test has stopped halfway. The process is basically copying the Test Case into an empty test Suite, and subsequently copying the Test Suite into an empty Test Configuration.

![Run a single Test Case](process-copy.png)

More in detail:

1. Edit the Test Case in MTA that needs to be single-tested using the <i class="fa fa-pencil" ></i> button;
2. Note the Test application that is selected for the Test Case;
3. Navigate to the Test Design (home)page;
4. Create a Test Configuration, and add the Test application that was noted in step 2;
5. Navigate back to the Test Configuration that contains the Test Case to be single-tested;
6. Create a Test Suite in this Test Configuration;
7. Navigate back to the Test Suite that contains the Test Case to be single-tested;
8. Select that Test Case;
9. Use the <i class="fa fa-copy" ></i> button on the Test Case to copy the Test Case;
10. Expand the "Choose another test suite, if the test case should not be copied to the current test suite:" groupbox, and select the Test Suite that was created in step 6 as target;
11. Navigate back to the Test Configuration (tip: use the breadcrumb feature on top of the Test Cases list, and click on "Test design overview");
12. Move the mouse over the Test Suite containing the single Test Case, to make the action buttons visible;
13. Use the <i class="fa fa-copy" ></i> button on the Test Suite to copy the Test Suite;
14. Expand the "Choose another test configuration, if the test suite should not be copied to the current test configuration:" groupbox, and select the empty Test Configuration that was created in step 4 as target;
15. Delete the Test Suite that was created in step 6 using the <i class="fa fa-trash-alt" ></i> button (since the actual intention was to move it, not to copy it);
16. Now it is possible to Execute the new Test Configuration that was created in step 4, with only one Test Suite, with only one Test Case.

## Tips and tricks

Below steps are optional, not mandatory, but will make it much easier to process test.

- Use the **MTA recorder** as a starting point. Read more about this in the How To section.
- Focus on building the Test Suites where the actual test is performed **first**.
- **Check results** in the Mendix app often, to check the progress.
- Then, **create masterdata** from scratch as much as possible, rather than reusing existing. This is to make sure the test always runs and there are no dependencies from the environment where the test is executed on.
- After that, always put a Test Suite to clean up, **before** the Test Suites for actual testing are executed. This makes it possible to visually inspect the result in the Mendix app being tested.
- When cleaning up, preferably use **existing (microflow) logic** to delete, rather than Delete Object Teststeps. This is to make sure associated objects or data generated from Domain Model Event handlers is also deleted.
- **Include asserts** to check the results of attribute values. Also create Object Count asserts after each Retrieve Object Teststep and each Microflow Teststep that returns an object or List.
- **Create datavariation**, to test with different values of the attributes. Make sure to also include the asserts in the datavariation. And finally, when creating multiple columns (variations) in the datavariation, only change one attribute value per variation. 

## Feedback?
Missing anything? [Let us know!](mailto:support@menditect.com)

Last updated 21 april 2022